import os
import re
import pandas as pd
import streamlit as st

from langchain_community.document_loaders import DataFrameLoader
from langchain_ollama import OllamaEmbeddings, OllamaLLM
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA

# -----------------------------------------------------------------------------
# M√≥dulo: interfaz_optimizada.py
# Descripci√≥n: Streamlit app optimizada para construir itinerarios formativos
#              con tiempos de respuesta reducidos usando caching y estructuras
# Autora: Esther M. Quintero (optimizada)
# -----------------------------------------------------------------------------

# Configuraci√≥n est√°tica
DISTRIBUTIONS = {
    "Resource type": [
        "Actividad desenchufada", "Programaci√≥n visual", "Actividad enchufada",
        "Curso", "V√≠deo", "Dispositivos f√≠sicos", "Programaci√≥n textual",
    ],
    "Values": [
        "Pensamiento cr√≠tico", "Fomento de la creatividad y del esp√≠ritu cient√≠fico",
        "Trabajo en equipo", "Buen uso de las TIC", "Convivencia y Educaci√≥n C√≠vica",
        "Atenci√≥n a la diversidad", "Educaci√≥n Ambiental y desarrollo sostenible",
        "Interculturalidad", "Igualdad de G√©nero", "Educaci√≥n para la Salud",
        "Fomento de la creatividad",
    ],
    "Key competences": [
        "Aprender a Aprender", "Competencia Matem√°tica y en Ciencia y Tecnolog√≠a",
        "Competencia Digital", "Sociales y C√≠vicas", "Comunicaci√≥n Ling√º√≠stica",
        "Pluriling√ºe",
    ],
    "Knowledge areas": [
        "Inform√°tica y Rob√≥tica", "Matem√°ticas", "√âtica", "Lengua y Literatura",
        "Arte", "Biolog√≠a y Geolog√≠a", "Filosof√≠a", "Geograf√≠a e Historia",
        "M√∫sica", "Deporte", "F√≠sica", "Tecnolog√≠a",
        "Ciencias (Biolog√≠a y Geolog√≠a)", "F√≠sica y Qu√≠mica",
        "F√≠sica (dentro de Biolog√≠a y Geolog√≠a)",
    ],
    "Cc concepts": [
        "Algoritmia y Programaci√≥n", "An√°lisis de Datos",
        "Impacto de la Computaci√≥n", "Sistemas Inform√°ticos",
        "Redes e Internet",
    ],
    "Ct skills": [
        "Razonamiento L√≥gico", "Descomposici√≥n", "Evaluaci√≥n",
        "Pensamiento Algor√≠tmico y Programaci√≥n", "Abstracci√≥n", "Patrones",
    ],
    "Duration": [
        "Actividad R√°pida (una sola clase)", "Sesi√≥n (hasta 2 horas)",
        "Semana (2-4 sesiones)", "Mes (5-15 sesiones)",
        "2 Meses (15-30 sesiones)", "M√°s de 3 Meses (M√°s de 30 sesiones)",
    ],
    "School years": [
        "1¬∫ ESO", "Tercer Ciclo EP", "2¬∫ ESO", "3¬∫ ESO", "Segundo Ciclo EP",
        "4¬∫ ESO", "1¬∫ Bachillerato", "2¬∫ Bachillerato", "Primer Ciclo EP",
        "Educaci√≥n Infantil",
    ],
    "Languages": ["Ingl√©s", "Espa√±ol"],
}
MODEL_OPTIONS = [
    "gemma3:1b", "llama3.2", "phi3", "moondream", "deepseek-r1:1.5b",
]

# -----------------------------------------------------------------------------
# Caching de datos y recursos para acelerar la aplicaci√≥n
# -----------------------------------------------------------------------------

@st.cache_data(ttl=3600)
def load_documents_from_excel(directory: str) -> list:
    """
    Carga y transforma archivos Excel en documentos para vectorizaci√≥n.
    Se usa caching para evitar recargas repetitivas.
    """
    docs = []
    for fname in os.listdir(directory):
        if not fname.lower().endswith(".xlsx"):  # solo xlsx
            continue
        path = os.path.join(directory, fname)
        df = pd.read_excel(path).fillna("")
        # Construir contenido de manera vectorizada
        df = df.astype(str)
        df["content"] = df.agg(" | ".join, axis=1)
        loader = DataFrameLoader(df, page_content_column="content")
        docs.extend(loader.load())
    return docs

@st.cache_resource
def build_chain(_documents: list, model_name: str) -> RetrievalQA:
    """
    Construye el RetrievalQA con embeddings y FAISS, cached por modelo.
    """
    emb = OllamaEmbeddings(model="nomic-embed-text")
    vect = FAISS.from_documents(_documents, emb)
    retr = vect.as_retriever(search_kwargs={"k": 4})
    llm = OllamaLLM(model=model_name)
    return RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retr,
        return_source_documents=False,
    )

# -----------------------------------------------------------------------------
# Funci√≥n para generar el prompt en espa√±ol
# -----------------------------------------------------------------------------

def build_prompt(selections: dict) -> str:
    lines = ["Genera un itinerario formativo que cumpla estos criterios:"]
    for cat, opts in selections.items():
        lines.append(f"- **{cat}**: {', '.join(opts)}")
    lines.append(
        "Sintetiza el programa en lista numerada, indicando duraci√≥n y justificando cada recurso. "
        "Incluye los enlaces de las actividades (columna 'URL') y redacta en Espa√±ol."
    )
    return "\n".join(lines)

# -----------------------------------------------------------------------------
# Interfaz Streamlit optimizada
# -----------------------------------------------------------------------------

st.set_page_config(page_title="Constructor de Itinerarios", layout="wide")
st.title("üß© Constructor de Itinerarios Formativos")

# Carga temprana de documentos
docs = load_documents_from_excel("../../data")

# Barra lateral: selecci√≥n de modelo y criterios
st.sidebar.header("Configuraci√≥n del LLM")
model = st.sidebar.selectbox(
    "Selecciona el modelo de Ollama", MODEL_OPTIONS,
    index=MODEL_OPTIONS.index("deepseek-r1:1.5b"), key="model_select"
)

st.sidebar.header("Selecciona caracter√≠sticas")
selections = {}
for cat, opts in DISTRIBUTIONS.items():
    chosen = st.sidebar.multiselect(cat, opts)
    if chosen:
        selections[cat] = chosen

# Construcci√≥n o reutilizaci√≥n de la cadena
if 'qa_chain' not in st.session_state or st.session_state.model != model:
    st.session_state.qa_chain = build_chain(docs, model)
    st.session_state.model = model

# Generaci√≥n de itinerario on demand
if st.sidebar.button("Generar Itinerario"):
    if not selections:
        st.warning("üö® Selecciona al menos una caracter√≠stica en la barra lateral.")
    else:
        prompt = build_prompt(selections)
        st.subheader("üîç Prompt generado")
        st.code(prompt, language="markdown")

        with st.spinner(f"Generando itinerario con {model}‚Ä¶"):
            raw = st.session_state.qa_chain.invoke(prompt)
        # Extraer respuesta
        content = raw.get('result') if isinstance(raw, dict) else raw
        cleaned = re.sub(r"<think>.*?</think>", "", content, flags=re.S).strip()

        st.subheader("‚úçÔ∏è Respuesta del Modelo")
        st.markdown(cleaned)
