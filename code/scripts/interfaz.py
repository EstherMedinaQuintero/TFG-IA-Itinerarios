import os
import re
import pandas as pd
import streamlit as st

from langchain_community.document_loaders import DataFrameLoader
from langchain_ollama import OllamaEmbeddings, OllamaLLM
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA

# -----------------------------------------------------------------------------
# M√≥dulo: interfaz.py
# Descripci√≥n: Streamlit app para construir itinerarios formativos
#              basados en selecciones de usuario y RetrievalQA
# Autora: Esther M. Quintero
# -----------------------------------------------------------------------------

# Constantes de configuraci√≥n
DISTRIBUTIONS: dict = {
    "Resource type": [
        "Actividad desenchufada", "Programaci√≥n visual", "Actividad enchufada",
        "Curso", "V√≠deo", "Dispositivos f√≠sicos", "Programaci√≥n textual",
    ],
    "Values": [
        "Pensamiento cr√≠tico", "Fomento de la creatividad y del esp√≠ritu cient√≠fico",
        "Trabajo en equipo", "Buen uso de las TIC", "Convivencia y Educaci√≥n C√≠vica",
        "Atenci√≥n a la diversidad", "Educaci√≥n Ambiental y desarrollo sostenible",
        "Interculturalidad", "Igualdad de G√©nero", "Educaci√≥n para la Salud",
        "Fomento de la creatividad",
    ],
    "Key competences": [
        "Aprender a Aprender", "Competencia Matem√°tica y en Ciencia y Tecnolog√≠a",
        "Competencia Digital", "Sociales y C√≠vicas", "Comunicaci√≥n Ling√º√≠stica",
        "Pluriling√ºe",
    ],
    "Knowledge areas": [
        "Inform√°tica y Rob√≥tica", "Matem√°ticas", "√âtica", "Lengua y Literatura",
        "Arte", "Biolog√≠a y Geolog√≠a", "Filosof√≠a", "Geograf√≠a e Historia",
        "M√∫sica", "Deporte", "F√≠sica", "Tecnolog√≠a",
        "Ciencias (Biolog√≠a y Geolog√≠a)", "F√≠sica y Qu√≠mica",
        "F√≠sica (dentro de Biolog√≠a y Geolog√≠a)",
    ],
    "Cc concepts": [
        "Algoritmia y Programaci√≥n", "An√°lisis de Datos",
        "Impacto de la Computaci√≥n", "Sistemas Inform√°ticos",
        "Redes e Internet",
    ],
    "Ct skills": [
        "Razonamiento L√≥gico", "Descomposici√≥n", "Evaluaci√≥n",
        "Pensamiento Algor√≠tmico y Programaci√≥n", "Abstracci√≥n", "Patrones",
    ],
    "Duration": [
        "Actividad R√°pida (una sola clase)", "Sesi√≥n (hasta 2 horas)",
        "Semana (2-4 sesiones)", "Mes (5-15 sesiones)",
        "2 Meses (15-30 sesiones)", "M√°s de 3 Meses (M√°s de 30 sesiones)",
    ],
    "School years": [
        "1¬∫ ESO", "Tercer Ciclo EP", "2¬∫ ESO", "3¬∫ ESO", "Segundo Ciclo EP",
        "4¬∫ ESO", "1¬∫ Bachillerato", "2¬∫ Bachillerato", "Primer Ciclo EP",
        "Educaci√≥n Infantil",
    ],
    "Languages": ["Ingl√©s", "Espa√±ol"],
}

MODEL_OPTIONS: list = [
    "gemma3:1b",
    "llama3.2",
    "phi3",
    "moondream",
    "deepseek-r1:1.5b",
]

@st.cache_data(ttl=3600)
def load_documents_from_excel(directory: str) -> list:
    """
    Carga documentos de archivos Excel y genera una lista de documentos.

    Args:
        directory (str): Ruta al directorio con archivos .xlsx.

    Returns:
        list: Documentos extra√≠dos con DataFrameLoader.
    """
    documents: list = []

    for filename in os.listdir(directory):
        if not filename.lower().endswith(".xlsx"):
            continue

        filepath = os.path.join(directory, filename)
        dataframe = pd.read_excel(filepath).fillna("")
        dataframe["content"] = dataframe.apply(
            lambda row: " | ".join(
                f"{col}: {row[col]}" for col in dataframe.columns
            ),
            axis=1
        )
        loader = DataFrameLoader(
            dataframe, page_content_column="content"
        )
        documents.extend(loader.load())

    return documents

@st.cache_resource
def build_chain(_documents: list, model_name: str) -> RetrievalQA:
    """
    Construye la cadena RetrievalQA con FAISS y embeddings de Ollama.

    Args:
        documents (list): Documentos a indexar.
        model_name (str): Nombre del modelo Ollama.

    Returns:
        RetrievalQA: Objeto configurado para consultas.
    """
    documents = _documents
    embeddings = OllamaEmbeddings(model="nomic-embed-text")
    vectorstore = FAISS.from_documents(documents, embeddings)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 4})
    llm = OllamaLLM(model=model_name)

    return RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        return_source_documents=False,
    )

def build_prompt(selections: dict) -> str:
    """
    Genera el prompt en Espa√±ol basado en las selecciones del usuario.

    Args:
        selections (dict): Mapeo de categor√≠a a opciones seleccionadas.

    Returns:
        str: Prompt formateado para enviar al modelo.
    """
    lines: list = ["Genera un itinerario formativo que cumpla estos criterios:"]

    for category, opts in selections.items():
        lines.append(f"- **{category}**: {', '.join(opts)}")

    lines.append(
        "Sintetiza el programa en lista numerada, indicando duraci√≥n y justificando "
        "cada recurso. Incluye los enlaces de las actividades (columna 'URL') "
        "y redacta en Espa√±ol."
    )

    return "\n".join(lines)

# Interfaz Streamlit
st.title("üß© Constructor de Itinerarios Formativos")

st.sidebar.header("Configuraci√≥n del LLM")
selected_model: str = st.sidebar.selectbox(
    "Selecciona el modelo de Ollama",
    MODEL_OPTIONS,
    index=MODEL_OPTIONS.index("deepseek-r1:1.5b"),
)

st.sidebar.header("Selecciona caracter√≠sticas")
user_selections: dict = {}
for category, options in DISTRIBUTIONS.items():
    chosen = st.sidebar.multiselect(label=category, options=options, default=[])
    if chosen:
        user_selections[category] = chosen

if st.sidebar.button("Generar Itinerario"):
    if not user_selections:
        st.warning("üö® Selecciona al menos una caracter√≠stica en la barra lateral.")
    else:
        prompt_text = build_prompt(user_selections)
        st.subheader("üîç Prompt generado")
        st.code(prompt_text, language="markdown")

        with st.spinner(f"Invocando al modelo {selected_model}‚Ä¶"):
            docs = load_documents_from_excel("./data")
            qa_chain = build_chain(docs, selected_model)
            raw_response = qa_chain.invoke(prompt_text)

        # Extraer texto y limpiar etiquetas internas
        if isinstance(raw_response, dict) and "result" in raw_response:
            content = raw_response["result"]
        else:
            content = raw_response

        cleaned = re.sub(
            r"<think>.*?</think>", "", content, flags=re.S
        ).strip()

        st.subheader("‚úçÔ∏è Respuesta del Modelo")
        st.markdown(cleaned)
